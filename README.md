# Итоговая работа. Поисковый движок "SearchEngine".

## Описание проекта.

### Общие данные.

Проект является веб-приложением на основе фреймворка __Spring Boot__, содержащий в себе 2 контроллера, несколько сервисов
и репозиториев для подключения к базе данных, а также frontend составляющую. Приложение представляет из себя JAR - файл, 
запускаемый на любом сервере или компьютере. Приложение работает с локально установленной базой данных MySQL, имеет 
простой ВЕБ - интерфейс и API, через который им можно управлять и получать результаты поисковой выдачи по запросу.

Данное приложение рекурсивно обходит сайты, данные которых указаны в файле __application.yaml__,
находящегося в папке __resources__, преобразует текст страниц этих сайтов в набор лемм и затем записывает информацию об 
этих леммах в базу данных. Далее на основе данной информации можно находить страницы на которых  содержится максимальное 
количество лемм из поискового запроса, введенного пользователем.

### Интерфейс приложения.

Веб-интерфейс (frontend-составляющая) проекта представляет собой одну веб-страницу с тремя вкладками:

__Dashboard__. Эта вкладка открывается по умолчанию. На ней отображается общая статистика по всем сайтам, а также детальная статистика и статус по каждому из сайтов (статистика, получаемая по запросу /api/statistics).

__Management__. На этой вкладке находятся инструменты управления поисковым движком — запуск и остановка полной индексации (переиндексации), а также возможность добавить (обновить) отдельную страницу по ссылке:

__Search__. Эта страница предназначена для тестирования поискового движка. На ней находится поле поиска, выпадающий список с выбором сайта для поиска, а при нажатии на кнопку «Найти» выводятся результаты поиска (по API-запросу /api/search):

Вся информация на вкладки подгружается путём запросов к API вашего приложения. При нажатии кнопок также отправляются запросы.

### Логика приложения.

Все классы находятся в папке src/main/java/searchengine. Это необходимо для правильной сборки и запуска приложения с помощью Maven.

Запуск приложения начинается с метода main, находящегося в классе Application, помеченном аннотацией @SpringBootApplication.

Поскольку Spring Boot включает в себя не только фреймворк Spring, но и веб-сервер Apache Tomcat, запущенное приложение сразу начинает «слушать» порт 8080 (по умолчанию) и при переходе в браузере по адресу http://localhost:8080/ начинает открываться главная страница приложения. Ниже мы детально разберём, как сделать, чтобы открывалась такая страница.

Сама веб-страница (файл index.html) размещена в папке resources/templates, поэтому её можно 
подключить в контроллере с помощью шаблонизатора Thymeleaf.

#### Контроллеры.

В папке controllers есть два контроллера: DefaultController и ApiController.

#####  DefaultController.

Собственно, в DefaultController создан метод index с аннотацией @RequestMapping("/"), которая означает, что этот метод должен вызываться при запросе к главной странице приложения.
В самом методе __index__ написан return “index”. Поскольку в проекте работает шаблонизатор Thymeleaf, такой код автоматически подключает и возвращает в качестве ответа код одноимённой веб-страницы (index.html), лежащей в папке resource.

##### ApiController.

Класс __ApiController__ помечен двумя аннотациями: @RestController и @RequestMapping("/api"). Первая означает, что этот контроллер будет работать по стандарту REST и, в частности, возвращать ответы в формате JSON. Вторая устанавливает префикс в пути запроса: все запросы, начинающиеся с /api, будут направляться на методы этого контроллера.
В контроллере также созданы объекты классов SearchLemmas, StatisticsService, IndexSites и ContentHandling (на самом деле это — интерфейсы, см. ниже) и в конструкторе ему присваивается передаваемое значение. Это сервис, который отвечает за формирование ответа на запрос /api/statistics. Ниже мы рассмотрим его детально.

В методе контроллера, который помечен аннотацией @GetMapping("/statistics") и, следовательно, отвечает на соответствующий GET-запрос, формируется успешный ответ:

		return ResponseEntity.ok(...);

Это — короткая запись, формирующая ответ в формате JSON с HTTP-кодом 200. В качестве параметра в метод ok передаётся результат выполнения метода getStatistics, вызываемого у объекта statisticsService.

В методе __startIndexing__, помеченного аннотацией  @GetMapping("/startIndexing"), если индексация уже не запущена, проиходит
вызов метода __index__ объекта indexSites и выдается ответ: 

       return ResponseEntity.ok(new Response(true, null));

либо если индексация уже запущена ответ будет:

       return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(new Response(false, errorResponse));

Класс __Response__, объекты которого используются в теле ответов, содержит в себе переменные __result__
и __error__ (boolean и String соответственно) которые содержат информацию о результате и причине
ошибки, если результат отрицательный. Класс Response расположен в папке dto.

Во всех последующих методах данного контроллера (кроме __searchLemma__) формат ответов схож с форматом метода __startIndexing__.
Разница только в значении переменной __error__ объекта класса __Response__.

В методе __indexSinglePage__, помеченном аннотацией  @PostMapping(value = "/indexPage") и содержащего параметр __url__,в случае, если сайт, адрес которого указан в 
запросе __url__, присутствует в списке файла __application.yaml__, вызывается метод __indexSingleSite__, объекта
__indexSites__. Если сайт отсутствует в списке, формируется ответ с сообщением об ошибке.

Метод __stopIndexing__, помеченный аннотацией @GetMapping("/stopIndexing"), в случае если индексация запущена, 
запускается метод __stopIndexing__ объекта __indexSites__. Если индексация не запущена, формируется ответ с сообщением об 
ошибке.

Метод __searchLemma__, помечен аннотацией @GetMapping(value = "/search") и 
содержит параметры (@RequestParam String query, String site, int offset, int limit). Параметр __query__ является фразой,
либо словом, которые нужно искать на сайте, адрес которого передан в параметре __site__, либо на всех сайтах
указанных в файле __application.yaml__, если параметр __site__ пуст. Если параметр __query__ передан, 
то формируется ответ:

         ResponseEntity.ok(searchLemmas.searchResult(query, site, offset, limit == 0 ? 20 : limit));

где в тело ответа передается метод __searchResult__ объекта __searchLemmas__ который возвращает информацию о результатах поиска.

Если же параметр __query__ не задан, то формируется ответ, такой же как в предыдущих трех методах:

         ResponseEntity.status(HttpStatus.BAD_REQUEST).body(new Response(false, errorResponse)))

Параметр __offset__  обозначает  сдвиг от 0 для постраничного вывода. 
Параметр __limit__ обозначает количество найденых страниц, которые нужно вывести(по умолчанию - 20).

#### Сервисы.

Сервисы приложения (классы и интерфейсы, выполняющие основную бизнес-логику) находятся в папке
__services__. 

В классе StatisticsServiceImpl сначала происходит подключение данных из файла конфигурации. Файл конфигурации (application.yaml) лежит в папке resources приложения и содержит список сайтов с их названиями и адресами.

Чтобы данные из файла конфигурации попали в сервис, в приложении сделано следующее:

Реализованы классы Site и SiteList. Они находятся в папке config. У них есть lombok-аннотации @Setter и @Getter, которые добавляют в классы сеттеры и геттеры для всех полей.

Класс SitesList помечен аннотациями @Component и @ConfigurationProperties(prefix = "indexing-settings"). Обратите внимание на значение prefix — это название ключа конфигурации, внутри которого лежит список сайтов. Аннотации приводят к автоматической инициализации объекта этого класса данными из файла application.yaml.

Класс сервиса StatisticsServiceImpl помечен lombok-аннотацией @RequiredArgsConstructor, которая добавляет в него конструктор с аргументами, соответствующими неинициализированным final-полям класса. В этом классе только одно такое поле — sitesList, поэтому будет добавлен конструктор только с этим аргументом. При создании объекта класса StatisticsServiceImpl в конструктор будет передан объект класса SitesList, который, как было сказано выше, автоматически инициализируется на основе данных конфигурации.

В методе сервиса getStatistics происходит постепенная сборка объекта класса StatisticsResponse из данных о сайтах из базы
данных.

##### Класс indexSitesImpl.

В классе __indexSitesImpl__ находятся методы для индексации, переиндексации и остановки индексации
(переиндексации) сайтов. Индексировать (переиндексировать) сайты можно как все сразу - при помощи метода __index__, так и 
поодиночке - при помощи метода __indexSingleSite__. Главное условие при индексации сайтов по отдельности - информация о сайте 
должна быть в конфигурационном файле (application.yaml):

Метод __index__ выполняет индексацию сайтов в многопоточном режиме. Количество потоков равно количеству сайтов,
которые нужно проиндексировать. В каждом потоке запускается метод __run__ cервиса __Task__, который
наследует интерфейс __Runnable__. В данном классе кроме метода __run__ содержатся методы __writeInSql__ и 
__reWriteInSql__ для индексации и переиндесации сайтов соответственно, а также для записи (перезаписи)
информации в базу данных.
Рекурсивный обход сайтов в данных методах осуществляется при помощи объектов
сервиса __SiteParser__, который рекурсивно обходит сайты в многопоточном режиме при помощи технологии
__forkJoin__. 
Превращение тестов страниц сайтов в набор лемм, сбор информации о леммах, а также запись информации
о леммах осуществляется при помощи методов класса __ContentHandlingImpl__.

Метод __indexSingleSite__ действует схожим образом, что и метод __index__, только индексация(переиндексация) выполняется
в одном потоке.

Метод __stopIndexing__ останавливает индексацию прерыванием всех потоков, выполняющих индексацию.

Остальные методы данного класса выполняют вспомогательную функцию для вышеописанных методов.

#### Класс SearchLemmasImpl

В классе __SearchLemmasImpl__ содержатся методы для поиска нужных фраз, либо слов (лемм) на сайтах,
указанных в конфигурационном файле (во всех сразу, либо в каком-то определенном), подсчет количеств найденных лемм на
каждой странице, подсчет встречаемости всех лемм на страницах сайта, вывод информации о поиске:

Методы __listOfLemmas__ превращают текст страниц сайта либо сайтов (если конкретный адрес не указан в запросе) в набор лемм,
подсчитывают количество раз которое данная лемма встречается на каждом сайте и возвращает список данных лемм в виде объектов
класса __Lemma__, содержащих информацию о каждой лемме. Превращение текста страниц в набор лемм осуществляется при помощи
методов сервиса __ContentHandlingImpl__.

Метод __shortedListOfLemmas__ убирает из списка, возвращенного методом __listOfLemmas__, леммы
которые встречаются на сайте слишком большое количество раз (имеют слишком большое число __frequency__).
В данном случае если самые распостраненные леммы, встречающиеся на сайте имеют  число __frequency__ больше либо равное
ста, то отфильтровываются леммы имеющие значение __frequency__ ,больше числа равного 80 % от максимального для данного сайта.
Если же самые распространенные леммы на сайте имеют число __frequency__ меньше ста, то все остается неизменным.

Метод __getListOfPages__ возвращает LinkedHashMap, где ключ это лемма, а значение - список страниц,
на которых данная лемма встречается.

Метод __recordInformationOfLemmas__ циклически обходит каждый список __page__ значений LinkedHashMap,
возвращаемый методом __getListOfPages__  и при помощи вложенного цикла, перебирающего keySet
данного LinkedHashMap, сопоставляет каждую лемму и каждую страницу каждого списка страниц, начиная с самого короткого
списка. При помощи метода __getRankByLemmaAndPage__ репозитория __SearchIndexRepository__, имеющего
два параметра - __pageId__ и __lemmaId__,метод получает ранк каждой леммы для данной страницы и отправляет
в сeт __listOfRelevance__. Затем, суммируя все значения данного списка, метод получает значение
__absoluteRelevance__ и отправляет его в список __listOfAbsoluteRelevance__. После этого значение __absoluteRelevance__
каждой страницы делится на максимальное значение списка __listOfAbsoluteRelevance__, получая значение
__relativeRelevance__. После всего этого для каждой страницы создается объект класса __InformationAboutLemmas__,
представлющий из себя информацию о наличии лемм из запроса на страницах сайтов. Класс содержит параметры
__site__, __siteName__, __url__, __title__, __snippet__, __relevance__. Параметр __snippet__ представляет
из себя фрагмент текста страницы, в котором встречаются леммы. Строку сниппета метод получает при 
помощи методов __getSnippet__ и __makeStringOfSnippet__. В параметр __relevance__вводится значение __relativeRelevance__. 
Каждый объект класса  __InformationAboutLemmas__ отправляется в список __listOfInformation__.

Метод __searchResult__ вызывает метод __recordInformationOfLemmas__, циклически обходит список
__listOfInformation__, создает список __data__, в который добавляет элементы списка __listOfInformation__
начиная с индекса равному параметру __offset__ и заканчивая индексом равному сумме параметров 
__offset__ и __limit__. Затем метод возвращает объект класса __InformationAboutSearching__,
c параметрами __result__, __count__, и __data__ (boolean, int и List<InformationAboutLemmas> соответственно),
в которые вносятся результат поиска, количество найденых страниц (длина списка __listOfInformation__ )
и список __data__, отсортированный по релевантности в обратном порядке.

##### Класс ContentHandlingImpl.

Данный класс содержит методы для работы с текстом страниц сайтов. Основные из них: __amountOfLemmas__
и __writeLemmasInSql__.

Метод __amountOfLemmas__ обрабатывает текст страницы, очищенный от html-тегов методом __cleanedPageContent__
преобразуя в набор лемм при помощи библиотеки __LuceneMorfology__. Затем леммы отправляются в 
HashMap __lemmas__, исключая при этом союзы, междометья и предлоги методом __unneededTypeOfWord__.
В __lemmas__ ключом является лемма, а значением - int, изначально равный 1. Если добавляется лемма,
которая уже есть в этой map, значение увеличивается на 1.

Метод __writeLemmasInSql__ перебирает в цикле список страниц для каждого сайта (сайт и список
страниц передаются в аргементы метода) и при помощи вложенного цикла, перебирающего мар возвращаемый
методом __amountOfLemmas__ и двух stringBuilder создаются две строки множественного insert-запроса
(для таблиц __lemma__ и __search_index__) которые передаются в метод __multiInsert__ репозитория
__MultiInsertRepository__. В поле rank таблицы __search_index__ передаются значения МАРы возвращаемой
методом __amountOfLemmas__. В поле __frequency__ таблицы __lemma__ передается 1, которое при 
помощи команды __ON DUPLICATE KEY__ в строке SQL-запроса увеличивается на 1. Duplicate key 
в таблице __lemma__ являются значения полей __site_id__ и __lemma__.

#### Репозитории.

В папке __repositories__ расположены классы-репозитории для работы со всеми таблицами базы данных
(lemma, page, site и search_index) и репозиторий __MultiInsertRepository__ для выполнения
SQL-запросов при помощи EntityManager, который создан для удобства создания множественных insert_запросов. 

#### Model.

В папке __model__ расположены классы-сущности для работы с таблицами базы данных, а также ENUM
__siteStatus__ для поля __status__ таблицы __site__.

#### Dto.

Все классы, на основе которых сервисом собирается итоговый объект, размещены в папке __dto__
и подпапке __statistics__. Аббревиатура DTO расшифровывается как Data Transfer Object, что
в переводе с английского означает «Объект передачи данных». Здесь размещены все классы для
создания объектов запросов и ответов и их составных частей.

#### База данных.

В приложении используется внешняя локально установленная база данных __MySQL__. В
ней создана схема __search_engine__, в которой созданы 4 таблицы: __site__, __page__,
__lemma__ и __search_index__. 

Таблица __site__ состоит из полей __id__, __last_error__, __name__, __status__, __status_time__,
и __url__. В таблицу выводится информация об состоянии и результате индексации сайтов.
В поле __status__ содержится информация о состоянии индексации ("INDEXING" - идет индексация сайта,
"INDEXED" - индексация прошла успешно и "FAILED" - если по каким-либо причинам индексация прервалась);
В поле __last_error__ выводится ошибка, в результате которой индексация не удалась; 
В поле __status_time__ выводятся дата и время появления каждого статуса.

Таблица __page__ содержит информацию о страницах, найденых в результате индексации.
В таблице имется поля: __id__, __code__, __content__ и __path__.
В поле __code__ выводится код HTTP-ответа, полученный при запросе страницы (например, 200, 404, 500 или другие);
В поле __content__ содержится текст страницы в формате HTML;
В поле __path__ - адрес страницы от корня сайта;

В таблице __lemma__ хранятся слова найденные на сайте. Таблица состоит из полей __id__, __frequency__,
__lemma__ и __site_id__.
В поле __frequency__ содержится количество страниц, на которых слово встречается хотя бы один раз; 
В поле __lemma__ - нормальная форма слова (лемма);
В поле __site_id__ - идентификатор сайта, на котором найдено данное слово.

В таблице __search_index__ хранится информация о количестве каждой леммы на каждой странице сайта.
Состоит из полей __id__, __page_id__, __lemma_id__ и __rank__.
Количество выводится в поле __rank__.

## Стек используемых технологий.

При создании приложения использовались следующие фреймворки и библиотеки:

* Пакет __Spring boot__ для простоты создания веб-приложений;
* __Jsoup__ для работы с html-содержимым страниц;
* __lombok__ для создания более лаконичного и аккуратного кода;
* Пакет __Apache Lucene__ для обработки текта страниц;
* Коннектор __MySQL connector__ для связи с базой данных;

## Инструкция по запуску приложения.

1. В корне проекта найдите Jar-файл __SearchEngine-1.0-SNAPSHOT.jar__;
2. Переместите файл к себе на устройство;
3. Установите на устройство __MySql server__ и __MySql Workbench__;
4. В __MySql Server__ - настройках адрес должен быть установлен по умолчанию (localhost:3306);
5. Создайте в __MySql__ схему __search_engine__. Кодировку схемы установите: Charset - utf8mb4, Collation - utf8mb4_general.c ;
6. Запустите Jar-файл из командной строки командой C:\Users\<имя пользователя>\<директория где находится файл>>Java -jar SearchEngine-1.0-SNAPSHOT.jar;
7. Откройте браузер и введите в строке поиска адрес http://localhost:8080;
8. При появлении интерфейса приложения зайдите во вкладку __management__ и нажмите на кнопку __start indexing__;
9. После того как во вкладке __dashboard__ появятся результаты индексации, зайдите во вкладку
__search__, выберите сайт из списка в окне сайтов (либо выберите все сайты), введите фразу для
поиска и нажмите кнопку __search__. Через какое-то время внизу должны появиться результаты поиска.





